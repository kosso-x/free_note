# GO
- ## 互联网协议
- /link
- ![[OSIq七层模型.png]]
- ### 物理层
  1. 网络接口：双绞线、光纤、无线电波等
- ### 数据链路层
  1. 定义电信号的协议 ***以太网***
  2. 一组电信号叫一帧，一帧包含两部分：
  * 标头：（发送者、接受者、数据类型）18个字节
  * 数据：46-1500个字节
  3. 以太网规定，接入网络的必须有网卡，网卡地址是独一无二的，叫做***MAC地址***；MAC地址 48个二进制为，常用12个16进制数表示，前6个是厂商编号，后6个是网卡流水号。
  4. MAC地址是广播的发送方式
- ### 网络层
  1. 定义了***网络地址***，在一个网络地址内叫子网，用MAC地址广播，不在子网内用网络地址路由转发
  2. 网络地址的协议叫***IP地址***，IPV4由32个二进制位组成，通常分为4段十进制数表示0.0.0.0~255.255.255.255
  3. IP数据包包含两部分：
  * 标头：（版本、长度、IP地址）20-60 字节
  * 数据：加标头总长度为 0-65535 字节
  4. <font color="#ff0000">网络层的主要工作是定义网络地址、区分网段、子网内MAC寻址、对于不同子网的数据包进行路由</font>
- ### 传输层
  1. 定义了***端口***概念，每个进程用不同的端口，0-1023 被系统占用，剩下的 1024-65535 分配给进程
  2. 端口协议 ***UDP协议***：比较简单，容易实现但是可靠性差，一旦数据包发出，无法知道对方是否收到。
  3. UDP数据包由两部分组成：
  * 标头：（发出端口和接收端口）8个字节
  * 数据：加标头总长度不超过65535
  4. 端口协议 ***TCP协议***：保证数据不会遗失，但是过程复杂，实现困难，消耗较多资源。
  5. TCP数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常TCP数据包的长度不会超过IP数据包的长度，以确保单个TCP数据包不必再分割。
  6. <font color="#ff0000">TCP协议三次握手以及为什么不是两次，不是四次：</font>
  * <font color="#ff0000">* 三次握手才可以阻止重复历史连接的初始化（主要原因）</font>
  * <font color="#ff0000">- 三次握手才可以同步双方的初始序列号</font>
  * <font color="#ff0000">- 三次握手才可以避免资源浪费</font>
  7. [三次握手](https://www.xiaolincoding.com/network/3_tcp/tcp_interview.html#tcp-%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E8%BF%87%E7%A8%8B%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84)
  8. [四次挥手](https://blog.csdn.net/yang731227/article/details/90637577)
  9. 常用的三个状态是：established 表示正在通信，time_wait 表示主动关闭，close_wait 表示被动关闭。
	- **服务器保持了大量TIME_WAIT状态**：time_wait是主动关闭连接的一方保持的状态，然后保持这个状态2MSL后，彻底关闭回收资源。
	  1. 防止上一次连接中的包，迷路后重新出现，影响新连接（经过2MSL，上一次连接中所有的重复包都会消失）
	  2. 可靠的关闭TCP连接。在主动关闭方发送的最后一个 ack(fin) ，有可能丢失，这时被动方会重新发fin, 如果这时主动方处于 closed 状态 ，就会响应 rst 而不是 ack。所以主动方要处于 TIME_WAIT 状态，而不能是 closed 。另外这么设计 time_wait 会定时的回收资源，并不会占用很大资源的，除非短时间内接受大量请求或者受到攻击。
	- **服务器保持了大量CLOSE_WAIT状态**：对方关闭了连接，程序没有检测到，没有关闭连接，所以 close_wait
		- I/O线程被意外阻塞，或I/O操作处理不及时
		- 一般是 程序有问题，没有关闭连接，或者响应太慢或者超时时间设置过小
		  10. 如何保证可靠传输： 
		  1. 超时重传：TCP发出一个段后，启动一个定时器，等待目的端确认收到这个报文段，如果不能及时收到这个确认，重发这个报文段
		  2. 校验和：保持首部和数据的校验和，如果收到段的校验和有差错，TCP将丢弃这个报文段和不确认收到此报文段
		  3. 流量控制：TCP连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据，当接收方来不及处理发送大的数据，能提示发送方降低发送的速率
		  4. 拥塞控制网络拥塞时，减少数据的发送
- ### 应用层（ftp，http，stmp，pop）
- #### 表示层
- 数据压缩，加密以及数据描述。这使得程序不必担心在各台主机中表示/存储的内部格式不同的问题
- #### 会话层
- 建立会话，如session认证，断点续传。通信的应用程序之间建立、维护和释放面向用户的连接。通信的应用程序之间建立会话，需要传输层建立一个或多个连接
  ***HTTP协议*** HTTP 协议是 Hyper Text Transfer Protocol（超文本传输协议）的缩写，是用于从<font color="#ff0000">万维网</font>（ WWW:World Wide Web：是一个透过[互联网](https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91 "互联网")访问的，由许多互相链接的[超文本](https://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC "超文本")组成的信息系统）服务器传输超文本到本地浏览器的传送协议。
- 简单快速
- 灵活
- 无连接
- 无状态
- 支持B/S C/S 模式
  客户端向服务器发送一个请求报文，请求报文包含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。
- ### 数据在各层之间的传递过程是怎么样的
  ![[数据在各层之间的传递过程.png]]
  在向下的过程中，需要添加下层协议所需要的首部或者尾部，而在向上的过程中不断拆开首部和尾部。
  ![[TCPIP协议.png]]
  TCP/IP协议是一种沙漏形状，中间小两边大，IP协议在其中占用举足轻重的地位
- ### get 和 post 的区别
  get 发送数据小
  get 不安全
  get 请求幂等
  get 用于获取信息
  post 修改服务器资源
- ### http 协议是无状态的
  协议对于事务处理没有记忆功能，服务器不知道客户端是什么状态，两次打开服务器上的网页没有关系
  http是一个面向连接的协议，不代表不能保持TCP连接
- ## Cookie 与 Session 与 JWT
  <font color="#ff0000">Cookie 与 Session就是为了弥补HTTP的无状态性</font>
  <font color="#ff0000">JWT 和 Session Cookies 就是用来处理在不同页面之间切换，保存用户登录信息的机制</font>
- ### session
  客户端请求服务端，服务端会为这次请求开辟一块`内存空间`，这个对象便是 Session 对象，服务器可以利用 Session 存储客户端在同一个会话期间的一些操作记录。
- session 如何判断是否是同一会话：
	- 服务端开辟session空间之后，客户端发送要求设置Cookie的响应，Cookie的过期时间为浏览器会话结束。接下来客户端每次向同一个网站发送请求时，请求头都会带上该 Cookie信息（包含 sessionId ）， 然后，服务器通过读取请求头中的 Cookie 信息，获取名称为 JSESSIONID 的值，得到此次请求的 sessionId。
- 缺点：A服务器存储了session，访问转到B服务器的时候，B 服务器并没有存储 A 的 Session，会导致 Session 的失效。
- ### cookie
- 作用
	- 会话管理：登陆、购物车、游戏得分或者服务器应该记住的其他内容
	- 个性化：用户偏好、主题或者其他设置
	- 追踪：记录和分析用户行为
- ### JWT
- 可以对用户进行身份验证，也可以用来在用户单击进入不同页面时以及登陆网站或应用程序后进行身份验证。
- JWT 主要由三部分组成，每个部分用 `.` 进行分割，各个部分分别是
	- `Header`：`令牌的类型(即 JWT)` 和使用的 `签名算法`
	- `Payload`：预定义声明 或 公共声明 或 自定义声明
	- `Signature`：JWT 的第三部分是一个签证信息，这个签证信息由三部分组成
		- header (base64后的)
		- payload (base64后的)
		- secret
- JWT 和 Session Cookies 的不同
	- 密码签名：
	- Json是无状态的：
	- 可扩展性：session 开销大
	- JWT支持跨域认证：
- ## HTTP 和 HTTPS
  1. http 是 HTTP 协议运行在TCP之上，所有传输内容都是明文，客户端和服务器端都无法验证对方的身份
  2. https 是 HTTP 运行在 SSL/TLS 之上，SSL/TLS 运行在TCP 之上。所有传输内容都经过加密
  3. https 协议需要用到ca申请证书
  4. http 是超文本传输协议，信息是明文传输，https 则是具有安全行的ssl 加密传输协议
  5. http 和 https 使用的是完全不同的连接方式，端口也不一样，80 443
  6. http 连接很简单，是无状态的
  7. https 协议是由 SSL + HTTP 协议构建的可进行加密传输、身份认证的网络协议比http协议更安全
- ## go语言slice和map底层实现原理
- ### slice:
  * 切片之间不能 == 或者 != ，可以通过 `reflect.DeepEqual` 函数来比较， 可以和nil比较
  * 扩容：
  * 1.18之前：小于1024时 翻倍，大于1024时每次扩容25%
  * 1.18之后：小于256时 翻倍，大于256 时 newcap = oldcap+(oldcap+3*256)/4
  * 声明 nil 值的切片：`var data []int`
- 声明零值的切片：`var data = []int{}`
- 改变切片源数据部分会改变原值，改变不属于源数据部分不会改变原值
- ### map
  * map 的 value可以是任何类型，key必须是可比较的类型
  * `B` 是 buckets 数组的长度的对数，通过获取到key的哈希，获取hash的后`B`位，转成十进制得到桶的位置，桶的数组大小就是 `2^B`，然后取hash的前8位，确定tophash，从桶里找tophash确定值
- ## 结构体不加tag可以转json字符串吗
  大写转成大写的
  小写转不了
- ## map进行有序的排序
  把 key 写在 slice 里，排列slice
- ## 拷贝大切片一定比小切片代价大吗
  一样：都是一个数组地址，长度和容量
- ## 对已关闭的chan进行读写，会怎么样
  写会报错
  读的话，要是还有值就能读，读取成功的返回值是true
  没值了，还能读到类型零值，读取成功的返回值是false
- ## Golang内存逃逸，什么情况下会内存逃逸
  * 内存逃逸：golang 程序变量会携带有一组校验数据，用来证明它的整个生命周是否在运行时完全可知。如果变量通过了这些校验，它就可以在栈上分配。否则就说它逃逸了，必须在堆上分配。
  * 能引起变量逃逸到堆上的典型情况：
  1. 在方法内把局部变量指针返回局部变量原应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此其生命周大于栈，则溢出。
  2. 发送指针或带有指针的值到 channel 中。在编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。
  3. 在一个切片上存储指针或带指针的值。一个典型的例子就是 []\*string。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。
  4. slice 的背后数组被重新分配了，因为 append 时可能会超出其容量Cap。 slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。
  5. 在 interface 类型上调用方法（例如调厍 fmtPrintIn （ a intetface{)))。 在 interface 类型上调用方法都是动态调度的一一方法的真正实现只能在运行时知道。想像一个 ioReader 类型的变 r 调用 r.Read(b) 会使得 r 的值和切片 b 的背后存傩都逃逸掉所以会在堆上分配。
- ## 字符串转成byte会发成内存拷贝吗
  会
- ## Go new 和 make 的主要区别
  make用于slice，map，和channel的初始化
  new 可以初始化全部类型，只分配内存
- ## go语言tcp udp具体实现原理
- ## go语言协程调度原理，协程为什么快
  G_M_P:
  * G：goroutine队列
  * M：内核级线程
  * P：内核数
  M会使用P处理一系列G，如果M1处理时间太长，会挂起，并把准备到M1处理的G分配到M2，M2执行完再回到M1，或者M2挂起后再到M1。处理完的M会帮助未处理完的M处理一半的G。
- ## go语言常见的一些算法
- ### 查找
- 线性查找：挨个查
- 二分查找：需要数据已经排序，数据划分，目标值与中间值比较，确定查找中间上还是中间下，然后继续二分
- 分块查找：
- 插值查找：
- ### 排序
- 冒泡排序：比较相邻的元素。如果第一个比第二个大，就交换他们两个。对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。
- 桶排序：数据分配到桶中，在桶内排序，然后按序读取
  -<font color="#ff0000"> 计数排序</font>：统计数组中每个值为 i 的元素出现的次数，存入统计数组的C\[i]，对所有计数累加，将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。
- 插入排序：挨个取值去对比后面的值，选择插入位置。
- 快速排序：挑一个元素，比他小的放到前面，大的放到后面，递归
- 基数排序：不好
- 选择排序：寻找最大或者最小的放大指定位置排序
- 希尔排序：看不懂
-
- ## es具体的使用方法好在哪里
- ## 主协程如何等其余协程完再操作
  wg.wait
  channl
  
  使用channel进行通信，context,select
- ## 什么是channel，为什么它可以做到线程安全
  Channel是Go中的一个核心类型，可以把它看成一个管道，通过它并发核心单元就可以发送或者接收数据进行通讯(communication),Channel也可以理解是一个先进先出的队列，通过管道进行通信。 Golang的Channel,发送一个数据到Channel 和 从Channel接收一个数据 都是 原子性的。而且Go的设计思想就是:不要通过共享内存来通信，而是通过通信来共享内存，前者就是传统的加锁，后者就是Channel。也就是说，设计Channel的主要目的就是在多任务间传递数据的，这当然是安全的。
  先进先出 队列
  通过通信来共享内存
- ## 查看Goroutine的数量
  runtime.NumGoroutine() 获取当前运行中的 goroutine 数量，通过它确认是否发生泄漏 runtime.GOMAXPROCS(5)
- ## Goruntine使用后的销毁
  https://www.topgoer.cn/docs/go_Language_100/go_Language_100-1fg4018d6l0rs
- ## Golang中除了加Mutex锁以外还有哪些方式安全读写共享变量
  channl
  原子操作
- ## Channl 是同步的还是异步的
  Channel是异步进行的。
  channel存在3种状态：
  nil，未初始化的状态，只进行了声明，或者手动赋值为nil
  active，正常的channel，可读或者可写
  closed，已关闭，千万不要误认为关闭channel后，channel的值是nil
- ## 怎么限制Goroutine的数量
  1.通过channel限制，每次执行的go之前向通道写入值，直到通道满的时候就阻塞了
  2.redis分布式锁,初始化100把锁，每次执行的go之前去redis拿一把锁，执行完了再放回去。直到没有锁可以拿为止
  3.sync.WaitGroup，Add()加1, Done()减一, Wait()主线程等待 用来控制计数器的数量
- ## Golang的runtime机制
  Runtime 负责管理任务调度，垃圾收集及运行环境。同时，Go提供了一些高级的功能，如goroutine, channel, 以及GC。  
  ​ 这些高级功能需要一个runtime的支持. runtime和用户编译后的代码被linker静态链接起来，形成一个可执行文件。
  ​ 这个文件从操作系统角度来说是一个user space的独立的可执行文件。  
  ​ 从运行的角度来说，这个文件由2部分组成，一部分是用户的代码，另一部分就是runtime。  
  ​ runtime通过接口函数调用来管理goroutine, channel及其他一些高级的功能。从用户代码发起的调用操作系统API的调用都会被runtime拦截并处理。  
  ​ Go runtime的一个重要的组成部分是goroutine scheduler。他负责追踪，调度每个goroutine运行，实际上是从应用程序的process所属的thread pool中分配一个thread来执行这个goroutine。  
  ​ 因此，和java虚拟机中的Java thread和OS thread映射概念类似，每个goroutine只有分配到一个OS thread才能运行。
- ## Select可以用于什么，常用于goroutine的完美退出
  golang的select就是监听IO操作，当IO操作发生时，触发相应的动作，每个case里必须是一个IO操作，准确来说是一个面向channl的IO操作。channel的零值是nil。也许会让你觉得比较奇怪，nil的channel有时候也是有一些用处的。因为对一个nil的channel发送和接收操作会永远阻塞，在select语句中操作nil的channel永远都不会被select到。
  
  通过channel控制生产者,从生产者端关闭channel 
  <font color="#ff0000">select可以用于什么，常用语gorotine的完美退出</font>
  
  情形一：M个接收者和一个发送者，发送者通过关闭用来传输数据的通道来传递发送结束信号。
  情形二：一个接收者和N个发送者，此唯一接收者通过关闭一个额外的信号通道来通知发送者不要再发送数据了。
  情形三：M个接收者和N个发送者，它们中的任何协程都可以让一个中间调解协程帮忙发出停止数据传送的信号。
- ## Channl 缓冲长度怎么决定
  channl 缓冲长度可以与上下游的速度比例成线性关系
- ## go 的Channl是怎么实现的
  golang的channel是个结构体，里面大概包含了三大部分：
  a. 指向内容的环形缓存区，及其相关游标
  b. 读取和写入的排队goroutine链表
  c. 锁
  任何操作前都需要获得锁， 当写满或者读空的时候，就将当前goroutine加入到recvq或者sendq中， 并出让cpu(gopark)
- ## Channl底层实现原理 环形数组，CSP模型
- ### CSP并发模型: 
  概念：以通信的方式来共享内存,用于描述两个独立的并发实体通过共享的通讯 channel（管道）进行通信的并发模型。 channel里面是一个队列，先进先出，负责协程之间通讯 go语言提倡不要通过共享内存来通信，而要通过通信来实现共享内存CSP并发模型
- ### 底层：
  是一个环形的数组，记录的信息有： buf:底层缓冲环形数组，有缓冲的channel使用 sendx:下一个数据读取下标 recvx:下一个数据写入下标 sendq:数据读取队列，包含头节点尾节点，记录哪个协程在等待，等待的是哪个channel,等待接收/发送的数据在哪里 recvq:数据写入队列 lock：线程安全锁 qcount:循环数组中元素的数量 datasize:循环数组的长度
- ### 环形数组好处： 
  环形数组消费元素只需要移动下标，普通数组消费元素，需要对剩余的数据前移
  ![[channl环形数组好处.png]]
- ## 退出程序时怎么防止Channl没有消费完
  优雅关闭channel
  不要在消费端关闭channel，不要在有多个并行的生产者时对channel执行关闭操作。
  也就是说应该只在[唯一的或者最后唯一剩下]的生产者协程中关闭channel，来通知消费者已经没有值可以继续读了。只要坚持这个原则，就可以确保向一个已经关闭的channel发送数据的情况不可能发生。
  
  channel关闭了，仍然可以读取channel剩余的数据
- ## Go原子性操作
- ### 互斥锁跟原子操作的区别
- 使用目的：互斥锁是用来保护一段逻辑，原子操作用于对一个变量的更新保护。
- 底层实现：`Mutex`由**操作系统**的调度器实现，而`atomic`包中的原子操作则由**底层硬件指令**直接提供支持，这些指令在执行的过程中是不允许中断的，因此原子操作可以在`lock-free`的情况下保证并发安全，并且它的性能也能做到随`CPU`个数的增多而线性扩展。
- ## 无缓冲Chan的发送和接收是否同步
  1. 发送和接收操作是同步的，即发送操作必须等待接收操作完成后才能继续执行，接收操作也必须等待发送操作完成后才能继续执行。
  2. 带缓冲通道是在被获取前能存储一个或者多个数据的通道，这种类型的通道并不强制要求Goroutine之间必须同时完成写入和获取。当通道中没有数据的时候，获取动作才会阻塞；当通道没有可用缓冲区存储数据的时候，写入动作才会阻塞。
- ## 协程和线程和进程的区别
- 进程：进程是系统进行资源分配和调度的一个独立单位，独立内存空间，切换开销大
- 线程：CPU调度和分派的基本单位，
- 协程：用户态的轻量级线程，切换基本没有开销
- ## 进程间的通信方式
- 通道 channl
- 共享内存 sync 包，Mutex 互斥锁
- ## 404状态码
  1. [信息响应](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status#%E4%BF%A1%E6%81%AF%E5%93%8D%E5%BA%94) (`100`–`199`)：接收的请求正在处理
  2. [成功响应](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status#%E6%88%90%E5%8A%9F%E5%93%8D%E5%BA%94) (`200`–`299`)：请求正常处理完毕
  3. [重定向消息](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status#%E9%87%8D%E5%AE%9A%E5%90%91%E6%B6%88%E6%81%AF) (`300`–`399`)：需要进行附加操作以完成请求
  4. [客户端错误响应](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status#%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%94%99%E8%AF%AF%E5%93%8D%E5%BA%94) (`400`–`499`)：服务器无法处理请求
  1. 400 错误请求，请求报文存在语法错误
  2. 401 身份认证，表示发送的请求需要有通过 HTTP 认证的认证信息
  3. 402 
  4. 403 访问权限，表示对请求资源的访问被服务器拒绝
  5. 404 无法识别url，表示在服务器上没有找到请求的资源
  6. 405 不支持的方法
  7. 406 
  8. 407 代理身份认证
  6. [服务端错误响应](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status#%E6%9C%8D%E5%8A%A1%E7%AB%AF%E9%94%99%E8%AF%AF%E5%93%8D%E5%BA%94) (`500`–`599`)：服务器处理请求出错
- ## 死锁条件，如何避免
  1. 使用顺序加锁：始终以相同的顺序加锁和解锁变量，以避免对同一个变量的互相等待。
  2. 使用适当的加锁方式：只对共享数据加锁，并使用读写锁或单线程操作来保护共享数据。
  3. 避免在加锁期间调用其他需要加锁的函数：在加锁期间调用其他加锁函数会导致死锁。
  4. 监控程序以确定是否存在死锁：使用工具，如 pprof 和 debug/pprof，可以帮助检测死锁。
- ## linux命令，查看端口占用，cpu负载，内存占用，如何发送信号给一个进程
  netstat -ntpl
  top
  df -h /free -d
  kill -15
- ## 项目里的消息推送怎么做的（业务有关）
  轮询，（客户端不断查询）
  长连接，（TCP/IP长连接，keep-alive）
  触发，
  定时
- ## 怎么防止重复消费（类似接口的幂等性），说了借助Redis或者数据库的事务
- ### 原因
- 前端重复提交：
- 接口超时重试：
- 消息重复消费：
- ### 解决方案
- 前端按钮置灰等
- 数据库唯一
- 定义唯一key并设置时间过期，然后存在redis里，请求前去找key
- 状态码
- ## Go的channel（有缓冲和无缓冲）
- 有缓冲：队列满了才能发送阻塞
- 无缓冲：发送和接收动作是同时的
- ## 用过的消息中间件
- sidekiq:
- 异步，削峰，解耦
- ## 单点登录
  使用sso登录凭证登录到一个可信的应用或者中央门户网站，通过身份验证后，sso生成一个回话身份验证令牌，包含用户名，电子邮件等信息，用户访问其他网站是，会像sso或IAM服务器合适确定用户是否通过回话验证，若通过，SSO 解决方案会使用由数字证书签署的身份验证令牌来验证用户，并为用户提供该应用的访问权限。 若未通过，则会提示用户重新输入登录凭证。
- ## 微服务
- ### Raft
  节点状态：跟随者，候选人，领导者
- Leader election (领导选举)：原来的leader挂掉后，必须选出一个新的leader
- Log replication (日志复制)：leader从客户端接收日志，并复制到整个集群中
- Safety (安全性)：如果有任意的server将日志项回放到状态机中了，那么其他的server只会回放相同的日志项
- ### 服务发现
  gRPC Resolver模块 有服务器和地址映射，client 建立连接时, 会根据 `URI scheme` 选取 resolver 模块中全局注册的对应 resolver。因此我们实现自己服务发现模块就是通过扩展全局注册自定义 `scheme resolver` 实现。
- ## 深拷贝，浅拷贝讲解下
- 浅拷贝只复制数据的顶层结构，而深拷贝会递归地复制所有数据。
- 使用浅拷贝时，修改拷贝后的对象中的引用类型数据会影响原始对象中的数据，而深拷贝则不会出现这种情况。
- 在进行数据复制时，根据需求选择合适的方式，以确保数据的正确性和独立性。
- # <font color="#ff0000">Go语言中，所有的参数传递都是值传递</font>
- ## Go语言中的并发安全性是什么？如何确保并发安全性？
  并发安全性是指在并发编程中，多个goroutine对共享资源的访问不会导致数据竞争和不确定的结果。
- 使用互斥锁（Mutex）
- 使用原子操作（Atomic Operations）
- 使用通道（channl）
- 使用同步机制：使用同步机制如等待组（WaitGroup）、条件变量（Cond）等来协调多个goroutine的执行顺序和状态。
- ## Mutex
- ### Mutex 两个字段：
  状态和信号量：协程之间的抢锁，实际上争抢给`Locked`赋值的权利，能给 `Locked` 置为1，就说明抢锁成功。抢不到就阻塞等待 `sema` 信号量，一旦持有锁的协程解锁，那么等待的协程会依次被唤醒。
- ### Mutex状态
  1. mutexLocked — 表示互斥锁的锁定状态；
  2. mutexWoken — 表示从正常模式被从唤醒；加锁和解锁过程中的通信。
  3. mutexStarving — 当前的互斥锁进入饥饿状态；
  4. waitersCount — Waiter 信息虽然也存在 state 中，其实并不代表状态。它表示阻塞等待锁的协程个数，协程解锁时根据此值来判断是否需要释放信号量。
- ### Mutex 正常模式和饥饿模式
- 正常模式（非公平锁）：所有等待锁的 goroutine 按照 FIFO（先进先出）顺序等待。被唤醒的goroutine会和新的goroutine竞争，新的更容易抢占，被唤醒的会加入到等到队列的前面。
- 饥饿模式（公平锁）：饥饿模式的触发条件：当一个 goroutine 等待锁时间超过 1 毫秒时，或者当前队列只剩下一个 goroutine 的时候，Mutex 切换到饥饿模式。为了解决了等待 goroutine 队列的长尾问题 饥饿模式下，直接由 unlock 把锁交给等待队列中排在第一位的 goroutine (队头)，同时，饥饿模式下，新进来的
- goroutine 不会参与抢锁也不会进入自旋状态，会直接进入等待队列的尾部。这样很好的解决了老的 goroutine 一直抢不到锁的场景。
- ### Mutex 自旋
  加锁时，如果当前 `Locked` 位为1，则说明当前该锁由其他协程持有，尝试加锁的协程并不是马上转入阻塞，而是会持续探测 `Locked` 位是否变为0，这个过程就是「**自旋**」。
  自旋的时间很短，如果在自旋过程中发现锁已经被释放，那么协程可以立即获取锁。此时即便有协程被唤醒，也无法获取锁，只能再次阻塞。
  自旋的好处是，当加锁失败时不必立即转入阻塞，有一定机会获取到锁，这样可以避免一部分协程的切换。
- ### 自旋条件（简单说就是不忙的时候才会启用自旋）
- 自旋次数要足够少，通常为 4，即自旋最多 4 次；
- CPU 核数要大于 1，否则自旋没有意义，因为此时不可能有其他协程释放锁；
- 协程调度机制中的 P 的数量要大于 1，比如使用 `GOMAXPROCS()` 将处理器设置为 1 就不能启用自旋；
- 协程调度机制中的可运行队列必须为空，否则会延迟协程调度。
- ## RWMutex 
  当有一个写锁的时候，将读锁的数量设置为负数。目的是让新进入的读锁等待之前的写锁释放通知读锁。当有写锁抢占时，也会等待之前的读锁都释放完毕。
- ### RWMutex注意事项
- 可以加一个写锁多个读锁
- 读锁占用的情况下会阻止写，不会阻止读
- 1. 写锁会阻止其他 Goroutine（无论读和写）进来，整个锁由该 Goroutine独占
- 适用于读多写少
- 未锁定时解锁会处罚panic
- ## Cond
  Cond 实现了一种条件变量，可以使用在多个 Reader 等待共享资源 ready 的场景（如果只有一读一写，一个锁或者 channel 就搞定了）
  每个 Cond 都会关联一个 Lock（\*sync.Mutex or \*sync.RWMutex），当修改条件或者调用 Wait 方法时，必须加锁，保护 condition。
- ### Broadcast 和 Signal 区别
  Broadcast 会唤醒所有等待 c 的 goroutine。调用 Broadcast 的时候，可以加锁，也可以不加锁。
  Signal 只唤醒 1 个等待 c 的 goroutine。调用 Signal 的时候，可以加锁，也可以不加锁。
- ## WaitGroup
  一个 WaitGroup 对象可以等待一组协程结束。使用方法是：
  1. main 协程通过调用 wg.Add(delta int) 设置 worker 协程的个数，然后创建 worker 协程；
  2. worker 协程执行结束以后，都要调用 wg.Done()
  3. main 协程调用 wg.Wait() 且被 block，直到所有 worker 协程全部执行结束后返回。
- ### WaitGroup 实现原理
- WaitGroup 主要维护了 2 个计数器，一个是请求计数器 v，一个是等待计数器 w，二者组成一个 64bit 的值，请求计数器占高 32bit，等待计数器占低32bit。
- 每次 Add 执行，请求计数器 v 加 1，Done 方法执行，等待计数器减 1，v 为0 时通过信号量唤醒 Wait()
- ### 什么是 sync.Once
- Once 可以用来执行且仅仅执行一次动作，常常用于单例对象的初始化场景。
- Once 常常用来初始化单例资源，或者并发访问只需初始化一次的共享资源，或者在测试的时候初始化一次测试资源。
- sync.Once 只暴露了一个方法 Do，你可以多次调用 Do 方法，但是只有第一次调用 Do 方法时 f 参数才会执行，这里的 f 是一个无参数无返回值的函数。
- ### sync.Pool 有什么用
  
  对于很多需要重复分配、回收内存的地方，sync.Pool 是一个很好的选择。频繁地分配、回收内存会给 GC 带来一定的负担，严重的时候会引起 CPU 的毛刺。而 sync.Pool 可以将暂时将不用的对象缓存起来，待下次需要的时候直接使用，不用再次经过内存分配，复用对象的内存，减轻 GC 的压力，提升系统的性能。
- ## 原子操作
  原子操作即是进行过程中不能被中断的操作，针对某个值的原子操作在被进行的过程中，CPU 绝不会再去进行其他的针对该值的操作。为了实现这样的严谨性，原子操作仅会由一个独立的 CPU 指令代表和完成。原子操作是无锁的，常常直接通过 CPU 指令直接实现。 事实上，其它同步技术的实现常常依赖于原子操作
- ### 原子操作和锁的区别
- 原子操作由底层硬件支持，而锁则由操作系统的调度器实现。
- 锁应当用来保护一段逻辑，对于一个变量更新的保护。
- 原子操作通常执行上会更有效率，并且更能利用计算机多核的优势，如果要更新的是一个复合对象，则应当使用 atomic.Value 封装好的实现。
- ## CAS
  CAS 的全称为 Compare And Swap，直译就是比较交换。是一条 CPU 的原子指令，其作用是让 CPU 先进行比较两个值是否相等，然后原子地更新某个位置的值，其实现方式是给予硬件平台的汇编指令，在 intel 的 CPU 中，使用的cmpxchg 指令，就是说 CAS 是靠硬件实现的，从而在硬件层面提升效率。
- ### 简述过程是这样：
  CAS需要有3个操作数：内存地址V，旧的预期值A，即将要更新的目标值B。CAS指令执行时，当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做。整个比较并替换的操作是一个原子操作。
- ## Go语言中的defer关键字有什么作用？请给出一个使用defer的示例。
  defer关键字用于延迟函数的执行，即在函数退出前执行某个操作。defer通常用于释放资源、关闭文件、解锁互斥锁等清理操作，以确保在函数执行完毕后进行处理。
- ## Go语言中的指针有什么作用？请给出一个使用指针的示例。
  指针是一种变量，存储了另一个变量的内存地址。通过指针，我们可以直接访问和修改变量的值，而不是对变量进行拷贝。
- # Mysql
- ## mysql索引分为几种（b+tree hash表）（O(log n)，O(n)）
- ### 储存方式区分
- B-树索引：全键值查询，可以排序，必须从左到右匹配
- <font color="#ff0000">任何查找都是从根节点到叶子节点的过程</font>
  ![[Btree索引.png]]
  如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。
- 哈希索引：速度快；建立索引更耗时，不支持范围和顺序查询，哈希通过整个索引值计算，不能单独计算。
- ### 逻辑区分
- 普通索引：单个索引
- 少数索引：组合索引 不允许重复值，允许空
- 主键索引：主键索引 属于特殊的少数索引，不允许值重复或者值为空
- 空间索引：不允许空
- 全文索引：只能在 CHAR、VARCHAR 或 TEXT 类型的列上创建
- ### 实际使用
- 单列索引：
- 多列索引：
- ### 索引几大原则 (<font color="#ff0000">拥有联合索引的表单查询，只有联合索引的第一个字段可以被索引</font>)
  1. 建议单张表索引不超过5个 
  2. 禁止使用全文索引
  3. 最左前缀匹配原则：比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。
  4. 可以乱序：
  5. 尽量选择区分度高的列作为索引
  6. 索引列不能参与计算
  7. 尽量的扩展索引
- ## 数据库如何建索引
  create index index_name
  on table_name (column1 [ASC|DESC], column2 [ASC|DESC], ...);
- ## Mysql 查询缓存
  ```
  query_cache_type=1
  query_cache_size=600000
  ```
- ## Mysql 日志
- ### 日志类型
- 错误日志
- 查询日志：默认是关闭的，
- 慢日志：记录Mysql查询超过指定时间的包
- 重做日志：
- 回滚日志：
- 二进制日志：默认关闭
- ### redo log是什么? 为什么需要redo log?
- redo log 是**重做日志**。
- 它记录了**数据页**上的改动。
- 它指**事务**中修改了的数据，将会备份存储。
- 发生数据库服务器宕机、或者脏页未写入磁盘，可以通过redo log恢复。
- 它是**Innodb存储**引擎独有的
  
  redo log主要用于MySQL异常重启后的一种数据恢复手段，确保了数据的一致性。
  配合数据库异步写回磁盘的技术
- ### 什么是WAL技术, 好处是什么.
- WAL，中文全称是Write-Ahead Logging，它的关键点就是日志先写内存，再写磁盘。MySQL执行更新操作后，**在真正把数据写入到磁盘前，先记录日志**。
- 好处是不用每一次操作都实时把数据写盘，就算crash后也可以通过redo log恢复，所以能够实现快速响应SQL语句。
- 防止误删除
- 容灾恢复
- 事务处理
- 降低IO成本
- ### 为什么有时候会感觉 MySQL 偶尔卡一下？
  如果偶尔感觉 MySQL 卡一下，可能是 MySQL 正在刷脏页，正在把内存中的更新操作刷到磁盘中。
- ### redo log 和 binlog 是怎么关联的?
  它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：
- 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；
- 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。
- ### MySQL 怎么知道 binlog 是完整的?
- statement 格式的 binlog，完整的标识是最后有 COMMIT 关键字。
- row 格式的 binlog，完整的标识是最后会有一个 XID event 关键字。
- ### 为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？
  因为 binlog 是不能“被打断的”，一个事务的 binlog 必须连续写，因此要整个事务完成后，再一起写到文件里。而 redo log 并没有这个要求，中间有生成的日志可以写到 redo log buffer 中，redo log buffer 中的内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中。
- ### 事务执行期间，还未提交，如果发生 crash，redo log 丢失，会导致主备不一致呢？
  不会，因为这时候 binlog 也还在 binlog cache 里，没发给备库，crash 以后 redo log 和 binlog 都没有了，从业务角度看这个事务也没有提交，所以数据是一致的。
- ### 在 MySQL 中用什么机制来优化随机读/写磁盘对 IO 的消耗？
  redo log 是用来节省随机写磁盘的 IO 消耗，而 change buffer 主要是节省随机读磁盘的 IO 消耗。redo log 会把 MySQL 的更新操作先记录到内存中，之后再统一更新到磁盘，而 change buffer 也是把关键查询数据先加载到内存中，以便优化 MySQL 的查询。
- ### Redo log 的写入方式
- redo log包括两部分内容，分别是内存中的**日志缓冲**(redo log buffer)和磁盘上的**日志文件**(redo log file)。
- mysql每执行一条DML语句，会先把记录写入**redo log buffer**，后续某个时间点再一次性将多个操作记录写到**redo log file**。这种先写日志，再写磁盘的技术，就是**WAL**。
  1. 日志最开始会写入位于存储引擎Innodb的redo log buffer，这个是在用户空间完成的。
  2. 然后再将日志保存到操作系统内核空间的缓冲区(OS buffer)中。
  3. 最后，通过系统调用`fsync()`，从**OS buffer**写入到磁盘上的**redo log file**中，完成写入操作。这个写入磁盘的操作，就叫做**刷盘**。
- ### Redo log的执行流程
  ![[Redolog的执行流程.png]]
  1. MySQL客户端将请求语句`update T set a =1 where id =666`，发往MySQL Server层。
  2. MySQL Server 层接收到SQL请求后，对其进行分析、优化、执行等处理工作，将生成的SQL执行计划发到InnoDb存储引擎层执行。
  3. InnoDb存储引擎层将**a修改为1**的这个操作记录到内存中。
  4. 记录到内存以后会修改redo log 的记录，会在添加一行记录，其内容是**需要在哪个数据页上做什么修改**。
  5. 此后，将事务的状态设置为prepare ，说明已经准备好提交事务了。
  6. 等到MySQL Server层处理完事务以后，会将事务的状态设置为**commit**，也就是提交该事务。
  7. 在收到事务提交的请求以后，**redo log**会把刚才写入内存中的操作记录写入到磁盘中，从而完成整个日志的记录过程。
- ### redo log 为什么可以保证crash safe机制呢？
  重启之后，redo log 会重新读写，然后恢复数据
- ### binlog的概念是什么, 起到什么作用, 可以保证crash-safe吗?
- bin log是归档日志，属于MySQL Server层的日志。可以实现**主从复制**和**数据恢复**两个作用。
- 当需要**恢复数据**时，可以取出某个时间范围内的bin log进行重放恢复。
- 但是bin log不可以做crash safe，因为crash之前，bin log**可能没有写入完全**MySQL就挂了。所以需要配合**redo log**才可以进行crash safe。
- ### binlog和redolog的不同点有哪些?
  
  |              | redo log                  | binlog                                |     |
  | ------------ | ------------------------- | ------------------------------------- | --- |
  | 作用           | 用于奔溃恢复                    | 主从复制和数据恢复                             |     |
  | 实现方式         | Innodb存储引擎实现              | Server层实现，所有的存储引擎都可以使用binlog日志        |     |
  | 记录方式         | 循环写的方式记录，写到结尾时，会回到开头重新写日志 | 通过追加的方式记录，当文件尺寸大于给配置值后，后续的日志会记录到新的文件上 |     |
  | 文件大小         | redo log 的大小是固定的          | 通过配置擦拭max_binlog_size 设置每个binlog 文件大小 |     |
  | crash-safe能力 | 具有                        | 没有                                    |     |
  | 日志类型         | 逻辑日志                      | 物理日志                                  |     |
- ### 执行器和innoDB在执行update语句时候的流程是什么样的?
- 执行器在优化器选择了索引后，会调用InnoDB读接口，读取要更新的行到内存中
- 执行SQL操作后，更新到内存，然后写redo log，写bin log，此时即为完成。
- 后续InnoDB会在合适的时候把此次操作的结果写回到磁盘。
- ### 如果数据库误操作, 如何执行数据恢复?
  数据库在某个时候误操作，就可以找到距离误操作最近的时间节点的bin log，重放到临时数据库里，然后选择误删的数据节点，恢复到线上数据库。
- ### binlog三种日志格式
- Statement：基于SQL语句的复制： 每一条会修改数据的sql都会记录在binlog中。
- Row:基于行的复制：不记录sql语句上下文相关信息，仅保存哪条记录被修改。
- Mixed:混合模式复制：实际上就是Statement与Row的结合
- ### 什么是MySQL两阶段提交, 为什么需要两阶段提交?
  1. redo log在写入后，进入prepare状态
  2. 执行器写入bin log
  3. 进入commit状态，事务可以提交。
  
  两阶段提交就是为了保证redo log和binlog数据的安全一致性。只有在这两个日志文件逻辑上高度一致了。你才能放心的使用redo log帮你将数据库中的状态恢复成crash之前的状态，使用binlog实现数据备份、恢复、以及主从复制。
- ### 如果不是两阶段提交, 先写redo log和先写bin log两种情况各会遇到什么问题?
- 先写redo log，crash后bin log备份恢复时少了一次更新，与当前数据不一致。
- 先写bin log，crash后，由于redo log没写入，事务无效，所以后续bin log备份恢复时，数据不一致。
- ### binlog刷盘机制
  事务提交之前会先写到binlog的缓存中，事务提交后，再将缓存中的数据写入到binlog日志文件中。缓存大小由参数 binlog_chache_size控制
  binlog 刷新磁盘 由参数 sync_binlog 控制
- 当`sync_binlog`为0时，表示MySQL不控制binlog的刷新，而是由系统自行判断何时写入磁盘。选这种策略，一旦操作系统宕机，缓存中的binlog就会丢失。
- `sync_binlog`为N时，每N个事务，才会将binlog写入磁盘。。
- 当`sync_binlog`为1时，则表示每次commit，都将binlog 写入磁盘。
- ### undo log 是什么？它有什么用
- undo log 叫做回滚日志，用于记录数据被修改前的信息。
- 它跟redo log重做日志所记录的相反，重做日志记录数据被修改后的信息。undo log主要记录的是数据的逻辑变化，为了在发生错误时回滚之前的操作，需要将之前的操作都记录下来，这样发生错误时才可以回滚。
- ### 说说Redo log 的记录方式
  redo log的大小是固定。它采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。
  ![[Redolog 的记录方式.png]]
  redo log buffer(内存中)是由首尾相连的四个文件组成的，它们分别是：ib_logfile_1、ib_logfile_2、ib_logfile_3、ib_logfile_4。
- write pos表示当前写入记录位置(写入磁盘的数据页的逻辑序列位置)
- check point表示刷盘(写入磁盘)后对应的位置。
- write pos到check point之间的部分用来记录新日志，也就是留给新记录的空间。
- check point到write pos之间是待刷盘的记录，如果不刷盘会被新记录覆盖。
  
  有了 redo log，当数据库发生宕机重启后，可通过 redo log将未落盘的数据（check point之后的数据）恢复，保证已经提交的事务记录不会丢失，这种能力称为**crash-safe**。
- ### 什么情况下会引发 MySQL 刷脏页（flush）的操作？
- 内存写满了，这个时候就会引发 flush 操作，对应到 InnoDB 就是 redo log 写满了；
- 系统的内存不足了，当需要新的内存页的时候，就会淘汰一些内存页，如果淘汰的是脏页这个时候就会触发 flush 操作；
- 系统空闲的时候，MySQL 会同步内存中的数据到磁盘也会触发 flush 操作；
- MySQL 服务关闭的时候也会刷脏页，触发 flush 操作。
- ### MySQL 刷脏页的速度很慢可能是什么原因
  在 MySQL 中单独刷一个脏页的速度是很快的，如果发现刷脏页的速度很慢，说明触发了 MySQL 刷脏页的“连坐”机制，MySQL 的“连坐”机制是指当 MySQL 刷脏页的时候如果发现相邻的数据页也是脏页也会一起刷掉，而这个动作可以一直蔓延下去，这就是导致 MySQL 刷脏页慢的原因了。
- ### 如何控制 MySQL 只刷新当前脏页？
  
  在 InnoDB 中设置 innodb _flush_ neighbors 这个参数的值为 0，来规定 MySQL 只刷当前脏页，MySQL 8 这个值默认是 0。
- ## Mysql锁
- ### 模式分类
- 乐观锁：一般不会冲突，适用于读多写少。
- 悲观锁：强烈的独占和排他性
- ### 粒度
- 全局锁：整个数据库实例加锁，加锁期间不能使用，启动一个事务必，用视图临时代替。 <font color="#ff0000">全库逻辑备份</font>
- 表锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。由于事务占用，先解决长事务。
- 页锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。
- 行锁：锁的是索引（对于UPDATE、DELETE和INSERT语句，InnoDb会自动给涉及数据集加排他锁）
	- 劣势：开销大，加锁慢，会出现死锁
	- 优势：锁的粒度小，发生锁冲突的概率低；处理并发的能力强
	- 注意事项：
		- update和delete时，where条件中字段没有命中唯一索引或者索引失效的话，就会导致扫描全表对表中的所有行记录进行加锁
- ### 属性（悲观锁）
- 共享锁：读锁 `SELECT ... FOR SHARE;`
- 排它锁：其他数据不能读写 `SELECT ... FOR UPDATE;`
- ### 状态（表级锁）
- 意向共享锁：事务有意向对表中的某些记录加共享锁（S 锁），加共享锁前必须先取得该表的 IS 锁、
- 意向排它锁：事务有意向对表中的某些记录加排他锁（X 锁），加排他锁之前必须先取得该表的 IX 锁。
- ### 算法（行锁）
- 间隙锁：锁定一个范围，不包括记录本身（创建记录时用）
- 记录锁：单个记录上锁
- 临键锁：锁定一个范围，包含记录本身（只能锁已存在的）
- ### 当前读和快读有什么区别
- 快照读：不加锁语法的 select 语句，如果读取的记录有锁，就会读快照数据
	- 在 RC 级别下，对于快照数据，一致性非锁定读总是读取被锁定行的最新一份快照数据。
	- 在 RR 级别下，对于快照数据，一致性非锁定读总是读取本事务开始时的行数据版本。
- 当前读：加锁select和insert，update，delete
- ## 数据库基础
  什么是关系型数据库：一种建立在关系模型的基础上的数据库。关系模型表明了数据库中所存储的数据之间的联系（一对一、一对多、多对多）。
  元组，码，候选码，主码，外码，主属性，非主属性
  ER图：
  实体、属性、联系
  三范式：
  1. 属性不可再分
  2. 1的基础上，取消了非主属性对于码的部分函数的依赖
  3. 2的基础上，取消了非主属性对于码的传递函数的依赖
  外键优缺点：
  1. 保证了数据库数据的一致性和完整性；
  2. 级联操作方便，减轻了程序代码量；
  1. 增加了复杂性
  2. 增加了额外工作
  3. 分库分表不友好
  drop、delete 与 truncate 区别？
	- drop(丢弃数据): drop table 表名，直接将表都删除掉，在删除表的时候使用。
	- truncate(清空数据) : truncate table 表名 ，只删除表中的数据，再插入数据的时候自增长 id 又从 1 开始，在清空表中数据的时候使用。
	- delete（删除数据）
- ## MySQL 主要具有下面这些优点：
  
  1. 成熟稳定，功能完善。
  2. 开源免费。
  3. 文档丰富，既有详细的官方文档，又有非常多优质文章可供参考学习。
  4. 开箱即用，操作简单，维护成本低。
  5. 兼容性好，支持常见的操作系统，支持多种开发语言。
  6. 社区活跃，生态完善。
  7. 事务支持优秀， InnoDB 存储引擎默认使用 REPEATABLE-READ 并不会有任何性能损失，并且，InnoDB 实现的 REPEATABLE-READ 隔离级别其实是可以解决幻读问题发生的。
  8. 支持分库分表、读写分离、高可用
- ## 字段类型
- 数值类型：int，bigint，float，double，decimal
- 字符串型：char，varchar，blob，text
- 日期时间类型：year，datetime，timestamp
- ## 整数类型的 UNSIGNED 属性有什么用？
  MySQL 中的整数类型可以使用可选的 UNSIGNED 属性来表示不允许负值的无符号整数。使用 UNSIGNED 属性可以将正整数的上限提高一倍
- ## CHAR和VARCHAR的区别？
  1. CHAR和VARCHAR类型在存储和检索方面有所不同
  2. CHAR列长度固定为创建表时声明的长度，长度值范围是1到255
  3. 当CHAR值被存储时，它们被用空格填充到特定长度，检索CHAR值时需删除尾随空格。
- ## DATETIME 和 TIMESTAMP 的区别是什么？
  TIMESTAMP 只需要使用 4 个字节的存储空间，但是 DATETIME 需要耗费 8 个字节的存储空间。但是，这样同样造成了一个问题，Timestamp 表示的时间范围更小。
- DATETIME：1000-01-01 00:00:00 ~ 9999-12-31 23:59:59
- Timestamp：1970-01-01 00:00:01 ~ 2037-12-31 23:59:59
- ## NULL 和 '' 的区别是什么？
  `NULL` 跟 `''`(空字符串)是两个完全不一样的值，区别如下：
- `NULL` 代表一个不确定的值,就算是两个 `NULL`,它俩也不一定相等。例如，`SELECT NULL=NULL`的结果为 false，但是在我们使用`DISTINCT`,`GROUP BY`,`ORDER BY`时,`NULL`又被认为是相等的。
- `''`的长度是 0，是不占用空间的，而`NULL` 是需要占用空间的。
- `NULL` 会影响聚合函数的结果。例如，`SUM`、`AVG`、`MIN`、`MAX` 等聚合函数会忽略 `NULL` 值。 `COUNT` 的处理方式取决于参数的类型。如果参数是 `*`(`COUNT(*)`)，则会统计所有的记录数，包括 `NULL` 值；如果参数是某个字段名(`COUNT(列名)`)，则会忽略 `NULL` 值，只统计非空值的个数。
- 查询 `NULL` 值时，必须使用 `IS NULL` 或 `IS NOT NULLl` 来判断，而不能使用 =、!=、 <、> 之类的比较运算符。而`''`是可以使用这些比较运算符的
- ## Mysql 基础架构
- **连接器：** 身份认证和权限相关(登录 MySQL 的时候)。
- **查询缓存：** 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。
- **分析器：** 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。
- **优化器：** 按照 MySQL 认为最优的方案去执行。
- **执行器：** 执行语句，然后从存储引擎返回数据。 执行语句之前会先判断是否有权限，如果没有权限的话，就会报错。
- **插件式存储引擎**：主要负责数据的存储和读取，采用的是插件式架构，支持 InnoDB、MyISAM、Memory 等多种存储引擎。
- ## 事务
- 原子性（Atomicity）：
- 一致性（Consistent）：
- 隔离性（Isolation）：
- 持久性（Durable）：
- ### 常见问题：
- **更新丢失**：当多个事务选择同一行操作，并且都是基于最初选定的值，由于每个事务都不知道其他事务的存在，就会发生更新覆盖的问题。
- **脏读**：事务A读取了事务B已经修改但尚未提交的数据。若事务B回滚数据，事务A的数据存在不一致性的问题。
- **不可重复读**：指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。
- **幻读**：事务A根据相同条件第二次查询到事务B提交的新增数据，两次数据结果集不一致。不符合事务的隔离性。
- ### 解决办法
- 锁（读写锁）
	- 共享锁（读锁）：
	- 排它锁（写锁）：
- MVCC：多版本并发控制方法，即对一份数据会存储多个版本，通过事务的可见性来保证事务能看到自己应该看到的版本。
	- 隐藏字段：用来判断当前版本数据的可见性
	- read view：用来判断当前版本数据的可见性
	- undo log：undo log 用于记录某行数据的多个版本的数据
- ### 事物隔离级别（<font color="#ff0000">MySQL 的隔离级别基于锁和 MVCC 机制共同实现的。</font>）
  
  | 隔离级别                   | 读数据一致性   | 脏读  | 不可重复 读 | 幻读  |
  | ---------------------- | -------- | --- | ------ | --- |
  | 未提交读(Read uncommitted) | 最低级别     | 是   | 是      | 是   |
  | 已提交读(Read committed)   | 语句级      | 否   | 是      | 是   |
  | 可重复读(Repeatable read)  | 事务级      | 否   | 否      | 是   |
  | 可串行化(Serializable)     | 最高级别，事务级 | 否   | 否      | 否   |
- ## Mysql规范
- ### 命名规范
- 数据库对象必须用小写字母并用下划线分割
- 数据库对象禁止使用Mysql关键字
- 数据库对象名字要见名识意，不要超过32个字符
- 临时库表必须以 `tmp_` 为前缀并以日期为后缀，备份表必须以 `bak_` 为前缀并以日期 (时间戳) 为后缀
- 所有存储相同数据的列名和列类型必须一致
- ### 数据库设计规范
- InnoDB存储引擎
- 表和库的字符集使用UTF8
- 表和字段加注释
- 控制表单数据量大小，建议控制在500万以内
- 谨慎使用Mysql分区表；跨分区查询效率低，建议采用物理分表
- 经常一起使用的列放到一个表中：减少关联
- 禁止在表中建立预留字段
- 禁止在数据库中存储文件
- 不要被数据库范式束缚
- 禁止在线上做数据库压力测试
- ### 数据库字段设计规范
- 优先选择符合存储需要的最小的数据类型
	- MySQL 提供了两个方法来处理 ip 地址
	- `INET_ATON()`：把 ip 转为无符号整型 (4-8 位)
	- `INET_NTOA()` :把整型的 ip 转为地址
- 避免使用enum类型
- 尽可能把所有列定义为NOT NULL因为Null 也是要占用存储空间的，计算时要对null做特别处理
- 不要字符串存储日期
- 财务相关的金额类数据必须使用decimal
- 单表不要包含过多字段
- ## 表类型
- 事物安全性
	- bdb
- 非事物安全型
	- heap：HEAP表是MySQL表中访问最快的表，主要是由于这类表使用保存期在内存中的散列索引，但必须注意的是，如果MySQL或者服务器崩溃，表中数据全部丢失。
	- isam：是MyISAM类型出现之前，MySQL表使用的默认类型，建议改用MyISAM。
	- mereg：由一组MyISAM表组成，之所合并主要出于性能上考虑，因为它能够提高搜索速度，提高修复效率，节省磁盘空间。
	- <font color="#ff0000">myisam</font>：MyISAM是MySQL表默认的类型，它是基于ISAM类型
	  1. 比ISAM表更小，所占资源更少
	  2. 可以在不同平台间二进制移植
		- <font color="#ff0000">InnoBDB</font>：新表 事务处理机制，崩溃后能立即恢复，支持外键功能，级联删除。支持并发能力。
- ## 简述在MySQL数据库中MyISAM和InnoDB的区别
  
  MyISAM：（MySQL 5.5 之前，MyISAM 引擎是 MySQL 的默认存储引擎）
- InnoDB 支持行级别的锁粒度，MyISAM 不支持，只支持表级别的锁粒度。
- MyISAM 不提供事务支持。InnoDB 提供事务支持，实现了 SQL 标准定义了四个隔离级别。
- MyISAM 不支持外键，而 InnoDB 支持。
- MyISAM 不支持 MVCC，而 InnoDB 支持。
- 虽然 MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是两者的实现方式不太一样。
- MyISAM 不支持数据库异常崩溃后的安全恢复，而 InnoDB 支持。
- InnoDB 的性能比 MyISAM 更强大。
  
  ```
  不支持事务，但是每次查询都是原子的；
  支持表级锁，即每次操作是对整个表加锁；
  不支持外键；
  存储表的总行数；
  一个MYISAM表有三个文件：索引文件、表结构文件、数据文件；
  采用非聚集索引，索引文件的数据域存储指向数据文件的指针。辅索引与主索引基本一致，但是辅索引不用保证唯一性。
  ```
  
  InnoDb：现在的默认引擎
  
  ```
  支持ACID的事务，支持事务的四种隔离级别；
  支持行级锁及外键约束：因此可以支持写并发；
  不存储总行数；
  一个InnoDb引擎存储在一个文件空间（共享表空间，表大小不受操作系统控制，一个表可能分布在多个文件里）
  也有可能为多个（设置为独立表空，表大小受操作系统文件大小限制，一般为2G），受操作系统文件大小的限制；
  主键索引采用聚集索引（索引的数据域存储数据文件本身），辅索引的数据域存储主键的值；
  因此从辅索引查找数据，需要先通过辅索引找到主键值，再访问辅索引；
  最好使用自增主键，防止插入数据时，为维持B+树结构，文件的大调整。
  ```
- ## 主键和候选键有什么区别？
  
  表格的每一行都由主键唯一标识,一个表只有一个主键。
  主键也是候选键。按照惯例，候选键可以被指定为主键，并且可以用于任何外键引用。
- ## myisamchk是用来做什么的？
  它用来压缩MyISAM表，这减少了磁盘或内存使用。
- ## MyISAM Static和MyISAM Dynamic有什么区别？
  在MyISAM Static上的所有字段有固定宽度。动态MyISAM表将具有像TEXT，BLOB等字段，以适应不同长度的数据类型。
  MyISAM Static在受损情况下更容易恢复。
- ## 如果一个表有一列定义为TIMESTAMP，将发生什么？
  每当行被更改时，时间戳字段将获取当前时间戳。
- ## 怎样才能找出最后一次插入时分配了哪个自动增量？
  LAST_INSERT_ID将返回由Auto_increment分配的最后一个值，并且不需要指定表名称。
- ## 你怎么看到为表格定义的所有索引？
  索引是通过以下方式为表格定义的：
  ```
  SHOW INDEX
  ```
- ## LIKE声明中的％和_是什么意思？
  ％对应于0个或更多字符，\_只是LIKE语句中的一个字符。
- ## 如何在Unix和Mysql时间戳之间进行转换？
  UNIX_TIMESTAMP：是从Mysql时间戳转换为Unix时间戳的命令 
  FROM_UNIXTIME：是从Unix时间戳转换为Mysql时间戳的命令
- ## BLOB和TEXT有什么区别？
  BLOB是一个二进制对象，可以容纳可变数量的数据。TEXT是一个不区分大小写的BLOB。
  BLOB和TEXT类型之间的唯一区别在于对BLOB值进行排序和比较时区分大小写，对TEXT值不区分大小写。
  <font color="#ff0000">TEXT 或 BLOB 类型只能使用前缀索引</font> 因为太长了
- ## mysql_fetch_array和mysql_fetch_object的区别是什么？
  mysql_fetch_array   – 将结果行作为关联数组或来自数据库的常规数组返回。
  mysql_fetch_object – 从数据库返回结果行作为对象。
- ## MyISAM表类型将在哪里存储，并且还提供其存储格式？
  每个MyISAM表格以三种格式存储在磁盘上：
  “.frm”文件 存储表定义
  数据文件具有“.MYD”（MYData）扩展名
  索引文件具有“.MYI”（MYIndex）扩展名
- ## 可以使用多少列创建索引？
  任何标准表最多可以创建16个索引列。
- ## MYSQL支持事务吗？
  autocommit 是否自动提交，开启事物操作时用到
- ## mysql有关权限的表都有哪几个？
  Mysql服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysql_install_db脚本初始化。这些权限表分别user，db，table_priv，columns_priv和host。
- ## MySQL数据库作发布系统的存储，一天五万条以上的增量，预计运维三年,怎么优化？
  1. 设计良好的数据库结构，允许部分数据冗余，尽量避免join查询，提高效率。
  2. 选择合适的表字段数据类型和存储引擎，适当的添加索引。
  3. mysql库主从读写分离。
  4. 找规律分表，减少单表中的数据量提高查询速度。
  5. 添加缓存机制，比如memcached，redis等。
  6. 不经常改动的页面，生成静态页面。
  7. 书写高效率的SQL。比如 SELECT * FROM TABEL 改为 SELECT field_1, field_2, field_3 FROM TABLE
- ## 列的字符串类型可以是什么？
  ```
  SET
  BLOB
  ENUM
  CHAR
  TEXT
  ```
- ## 锁的优化策略
  
  1. 读写分离
  2. 分段加锁
  3. 减少锁持有的时间
  4. 多个线程尽量以相同的顺序去获取资源
  不能将锁的粒度过于细化，不然可能会出现线程的加锁和释放次数过多，反而效率不如一次加一把大锁。
- ## 索引的底层实现原理和优化
  B+树，经过优化的B+树
  主要是在所有的叶子结点中增加了指向下一个叶子节点的指针，因此InnoDB建议为大部分表使用默认自增的主键作为主索引。
- ## 什么情况下设置了索引但无法使用
  1. 以“%”开头的LIKE语句，模糊匹配
  2. OR语句前后没有同时使用索引
  3. 数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）
- ## 实践中如何优化MySQL
  1. SQL语句及索引的优化
  2. 数据库表结构的优化
  3. 分段查询
  4. 系统配置的优化    
  5. 硬件的优化
- ## 优化数据库的方法
- 选取最适用的字段属性，尽可能减少定义字段宽度，尽量把字段设置NOTNULL，例如’省份’、’性别’最好适用ENUM
- 使用连接(JOIN)来代替子查询
- 适用联合(UNION)来代替手动创建的临时表
- 事务处理
- 锁定表、优化事务处理
- 适用外键，优化锁定表
- 建立索引
- 优化查询语句
- ### 读写分离
	- 添加代理层，MySQL Router，MySQL Proxy
	  1.  部署多台数据库，选择其中的一台作为主数据库，其他的一台或者多台作为从数据库。
	  2. 保证主数据库和从数据库之间的数据是实时同步的，这个过程也就是我们常说的**主从复制**。
	  3. 系统将写请求交给主数据库处理，读请求交给从数据库处理。
	- 主从复制
	  1. 主库将数据库中数据的变化写入到 binlog
	  2. 从库连接主库
	  3. 从库会创建一个 I/O 线程向主库请求更新的 binlog
	  4. 主库会创建一个 binlog dump 线程来发送 binlog ，从库中的 I/O 线程负责接收
	  5. 从库的 I/O 线程将接收的 binlog 写入到 relay log 中。
	  6. 从库的 SQL 线程读取 relay log 同步数据本地（也就是再执行一遍 SQL ）。
	- 避免主从延迟
	  1. 将那些必须获取最新数据的读请求都交给主库处理
	  2. 延迟读取
- ### 分库分表
- **垂直分库**： 就是把单一数据库按照业务进行划分，不同的业务使用不同的数据库，进而将一个数据库的压力分担到多个数据库。
- **水平分库**： 是把同一个表按一定规则拆分到不同的数据库中，每个库可以位于不同的服务器上，这样就实现了水平扩展，解决了单表的存储和性能瓶颈的问题。
- **垂直分表**： 是对数据表列的拆分，把一张列比较多的表拆分为多张表。
- **水平分表**： 是对数据表行的拆分，把一张行比较多的表拆分为多张表，可以解决单一表数据量过大的问题。
- 成本：
	- join操作
	- 事务问题
	- 分布式主键
	- 跨库聚合查询
- 方案：ShardingSphere
- 迁移库：canal
- ### 冷热分离（<font color="#ff0000">TiDB</font>）
  1. 时间维度划分
  2. 使用频率划分
  3. 优点：热数据的查询性能得到优化
  4. 缺点：增加系统复杂性和风险
- # Redis
  ```
  redis-cli -h 192.168.0.110 -p 6379 -a 123456
  -raw 防止中文乱码
  auth 身份认证
  exists key 判断是否存在
  del key 删除
  ```
- ### Redis基本数据结构
- String（字符串）：
- List（列表）：双向链表；消息队列
- Set（集合）：就是一个集合 无序数组
- Hash（散列）：结构化数据
- Zset（有序集合）：有序数组
- ### Redis相比memcached有哪些优势
- memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型
- redis的速度比memcached快很多
- redis可以持久化其数据
- ### Reids6种淘汰策略
- LRU：最近做少使用，最近使用过的可能近期也会大量使用。
- LFU：最近最少次数使用，最近没使用的，可能未来也很少使用。
- noeviction: **不删除策略**, 达到最大内存限制时, 如果需要更多内存, 直接返回错误信息。大多数写命令都会导致占用更多的内存(有极少数会例外。
- allkeys-lru:**所有key通用; 优先删除最近最少使用(less recently used ,LRU) 的 key**。
- volatile-lru:**只限于设置了 expire 的部分; 优先删除最近最少使用(less recently used ,LRU) 的 key**。
- allkeys-random:**所有key通用; 随机删除一部分 key**。
- volatile-random: **只限于设置了 expire 的部分; 随机删除一部分 key**。
- volatile-ttl: **只限于设置了 expire 的部分; 优先删除剩余时间(time to live,TTL) 短的key**。
- ### Redis的并发竞争问题如何解决
- 单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，利用setnx实现锁。
- ### setnx 实现锁
- 进程A要访问某资源时，需要创建一个唯一key，然后setnx 这个key，这时候 key 是有值的，其他进程访问这个资源时，发现key有值就代表以上锁。进程A使用完之后需要删除key。
- 注意：
	- 设置key要设置expire，防止忘记删除key导致长时间锁；
	- 设置 key 的值，尽量与当前进程有关，操作时间大于expire时间后，误删除其他进程创建的key
- ### Redis是单线程的，但Redis为什么这么快
- 内存存储：
- 数据结构优化：Redis使用了高度优化的数据结构，如散列表。这些数据结构使得数据访问更高效，尤其是在执行大量的读或写操作时。
- 单线程模型：避免了线程切换和竞态条件
- 无需磁盘I/O操作：
- 支持多种数据类型：针对不同类型提供高效存储和访问
- 查询语言简单：
- 持久化策略灵活性：Redis提供了多种持久化选项，如RDB快照和AOF日志文件。用户可以根据需求选择适当的持久化策略，平衡速度和数据安全性。
- ### 为什么Redis是单线程的
- ### Redis内存模型
- used_memory：**Redis分配器分配的内存总量（单位是字节）**，包括使用的虚拟内存（即swap）；Redis分配器后面会介绍。used_memory_human只是显示更友好。
- used_memory_rss：**Redis进程占据操作系统的内存（单位是字节）**，与top及ps命令看到的值是一致的；除了分配器分配的内存之外，used_memory_rss还包括进程运行本身需要的内存、内存碎片等，但是不包括虚拟内存。
- mem_fragmentation_ratio：**内存碎片比率**，该值是used_memory_rss / used_memory的比值
- mem_allocator：**Redis使用的内存分配器**，在编译时指定；可以是 libc 、jemalloc或者tcmalloc，默认是jemalloc；截图中使用的便是默认的jemalloc。
- ### Redis内存划分
- 进程本身运行需要的内存
- 数据
- 缓冲内存
- 内存碎片
- ### Redis对象有5种类型
  无论是哪种类型，Redis都不会直接存储，而是通过redisObject对象进行存储。
- ### Redis没有直接使用C字符串
  (即以空字符’\0’结尾的字符数组)作为默认的字符串表示，而是使用了SDS。SDS是简单动态字符串(Simple Dynamic String)的缩写。<font color="#ff0000">Reidis的SDS在C字符串的基础上加入了free和len字段。</font>
- ### Reids主从复制
  复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制
- ### Redis哨兵
  在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制。
- ### Reids持久化触发条件
  RDB持久化的触发分为手动触发和自动触发两种。
- ### Redis 开启AOF
  Redis服务器默认开启RDB，关闭AOF；要开启AOF，需要在配置文件中配置：
  appendonly yes
- ### 缓存穿透、缓存击穿、缓存雪崩
  通常查询逻辑是为了避免每次都到持久层（如 mysql）中获取数据，可以先到缓存（如 Redis）中获取；如果缓存中获取不到，才到数据库中获取，同时将获取到的数据缓存到 redis 中。加缓存的目的是让用户尽可能少的访问数据库，尽可能多的访问缓存数据，从而提高网站的响应速度，保证网站的高并发，保护持久层数据的安全，同时提升用户的体验。
- #### 缓存穿透：<font color="#ff0000">查询缓存中不存在的数据会导致缓存穿透。</font>
  低频的缓存穿透是不可避免的，但是需要避免高频的缓存穿透。如果有人恶意并发访问数据库中不存在数据，就可能会导致数据库因扛不住大的并发而引起系统瘫痪。
	- 解决办法：
	  1. 当 redis 没有命中该数据时，请求会到达 mysql；如果 mysql 也不存在该数据时，则缓存一个空对象到 redis 中并设置过期时间。这样就可以解决缓存穿透问题。
	- 缺点：
		- 可能缓存大量空值，可能把有用数据淘汰掉
		- 可能导致过期之前，redis和数据库数据不匹配
	- 解决办法：
	  2. 布隆过滤器：查之前先检验一下数据是否合法，合法再下发，不合法就返回
	- 缺点：
		- **Bloom Filter** 哈希碰撞
- #### 缓存击穿：<font color="#ff0000">当某个数据被高并发访问时，如果这个数据 redis 的 key 的突然失效，会导致这些请求同一时间打到数据库，数据库扛不住就会导致系统瘫痪</font>
	- 解决方案
		- 1. 热点数据不过期
	- 缺点：
		- 数据库和redis数据不一致
	- 解决方案
		- 2. 分布式锁
- #### 缓存雪崩：<font color="#ff0000">缓存击穿是一个热点 key 的失效，而缓存雪崩是多个热点 key 同时失效。</font>
  缓存过期的时间比较一致，某一时刻 key 大面积失效。解决办法：将缓存时间设置成一个随机数。
  redis 挂了，或因为网络抖动访问不了 redis 了。解决办法：使用 redis 集群。
	- 解决方案
		- 1. 数据预热，缓存时间随机：启动项目时，将数据缓存到redis,并设置随机失效时间，再隔     一段时间同步数据.
		- 2. redis 集群：
- ### 缓存和数据库数据不一致
- 用新的更新旧的
- canal是由Alibaba开源的一个基于binlog的增量日志组件，其核心原理是canal伪装成Mysql的slave，发送dump协议获取binlog，解析并存储起来给客户端消费。
- ### Reids主从复制
  复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。
  <font color="#ff0000">原则：</font>主会同步数据到从，从不会同步数据到主，主负责写数据，从负责读数据。
  master最好不要做快照，可以给从开日志
- ### Redis哨兵
  在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制。
- ### RDB和AOF的优缺点
- RDB持久化
	- 优点：RDB文件紧凑，体积小，网络传输快，适合全量复制；恢复速度比AOF快很多。当然，与AOF相比，RDB最重要的优点之一是对性能的影响相对较小。
	- 缺点：RDB文件的致命缺点在于其数据快照的持久化方式决定了必然做不到实时持久化，而在数据越来越重要的今天，数据的大量丢失很多时候是无法接受的，因此AOF持久化成为主流。此外，RDB文件需要满足特定格式，兼容性差（如老版本的Redis不兼容新版本的RDB文件）。
- AOF持久化
	- 与RDB持久化相对应，AOF的优点在于支持秒级持久化、兼容性好，缺点是文件大、恢复速度慢、对性能影响大。
- ### Redis还提供的高级工具
  像慢查询分析、性能测试、Pipeline、事务、Lua自定义命令、Bitmaps、HyperLogLog、发布/订阅、Geo等个性化功能。
- ### 读写分离模型
  通过增加Slave DB的数量，读的性能可以线性增长。为了避免Master DB的单点故障，集群一般都会采用两台Master DB做双机热备，所以整个集群的读和写的可用性都非常高。读写分离架构的缺陷在于，不管是Master还是Slave，每个节点都必须保存完整的数据，如果在数据量很大的情况下，<font color="#ff0000">集群的扩展能力还是受限于单个节点的存储能力</font>，而且对于Write-intensive类型的应用，读写分离架构并不适合。
- ### Redis做异步队列
  list 列表做队列，
- ### Redis中海量数据的正确操作方式
  利用SCAN系列命令（SCAN、SSCAN、HSCAN、ZSCAN）完成数据迭代。
  （类似数据库分页取数据）
- SCAN的参数没有key，因为其迭代对象是DB内数据；
- 返回值都是数组，第一个值都是下一次迭代游标；
- 时间复杂度：每次请求都是O(1)，完成所有迭代需要O(N)，N是元素数量；
- ### Redis 事务不支持回滚
- ### LRU 算法
- 缓存的数据大小。
- 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。
- 数据量大于指定的缓存个数的时候，就自动删除最老的数据。
- ### Redis 中设置过期时间主要通过以下四种方式
- 多长时间后过期
- 某时间点后过期
- ### 多节点 Redis 分布式锁：Redlock 算法
  向N个节点获取锁，设置获取锁超时时间，超时时间小于锁的时间，
  大多数获取锁，重新设置锁的有效时间
  否则释放锁。
- ### Reids三种不同删除策略
  定时删除：过期时间定时任务，占用CPU
  惰性删除：用的时候检查过期时间，不释放内存
  定期删除：
- ### Redis常见的几种缓存策略
- 旁路缓存模式：查数据，有缓存用缓存，没缓存程序查询用数据库，然后写缓存
- 读穿透模式：查数据，有缓存用缓存，没缓存，缓存自己找数据，然后写缓存
- 写穿透模式：写到缓存，缓存写到数据库
- 异步缓存写入模式：
- ### Redis 到底是怎么实现“附近的人”
  附近地区的人存到一个集合里
- ### redis性能测试工具
- redis-benchmark：模拟N个客户端同时发送总数M个查询
- # Gin
- ## 简单介绍一下 Gin 框架 (为什么选择Gin框架)？
- Gin框架 是基于 **Go语言** 开发的一个 **轻量级Web应用开发框架**。
- - gin 框架中采用的路由库是基于httprouter做的，所以 **性能很好**。
- 路由是树状结构
- 支持路由分组
- 启动新的goroutine时，不应该使用原始上下文，必须使用它的只读副本
- ## 你还知道那些框架 (Echo、Beego)？有什么特点？
  > - **`Echo`**: 比 **gin框架** 更轻量, 非常适合于开发 **轻量级的微服务**。
  > - **`Beego`**: **模块很全**, 适合开发 **工业级项目**。MVC
- ## 谈谈你对 protocol buffers 的理解？
  > **`Protocol Buffers` (protobuf)** 是 除了 **json** 和 **xml** 之外的另一种 **数据传输方式**。
  > 一条 **数据**，用 **protobuf** 序列化后的大小是 **json** 的 **10分之一**, 性能却是它的 **5~100倍**。
  > **`缺点`**: 由于是 **二进制格式** 存储的，所以 **可读性较差**。
  ## Gin框架的开发步骤？
  > 1. **加载配置**: 通过 **`github.com/spf13/viper`** 指定 **配置文件**，并从 **配置文件** 中加载 **配置信息**。
  > 2.初始化 **MySQL** 配置、**Redis** 配置、**日志** 配置等。
  > 3.初始化**路由配置**，**注册路由**。
  > 4.**启动项目: r.Run()**。
- ## YAML 配置的优势在哪里 ?
  > 1.**减少了重复的前缀, 方便阅读**
  > 2.**支持数组**
- ## 什么是 viper？
  > **viper** 是基于 **Go语言** 实现的 **配置解决方案**, 具有 **丰富的特性**。
  >
  > - 支持 **YAML** / **JSON** 等多种格式的配置文件。
  > - 可以设置 **监听配置文件** 的 **修改操作**。
- ## Gin语言 中的 中间件 有什么作用？
  > - **中间件 middlewares** 在 **Gin框架** 起到了 **功能层** 的作用。
  > - 当用户提交了 **数据请求** 时，**功能层** 负责将这些请求进行 **预处理**，再向数据库发出 **数据交互**。
- ## 中间件 middlewares 怎么使用的，中间件有几种类型？
  中间件 **`middlewares`** 使用 **`use`** 方法。中间件按 **作用范围** 可分为三种：
- **`全局`中间件**: **例: router.Use(Logger(), Recovery())**
- **`路由组`中间件**: **例: userRouter := router.Group("/user", CookieMiddleware())**
- **`单个路由`中间件**: **例: router.GET("/login", LoginMiddleware, loginHandler)**。
- ## Gin框架中怎么实现 参数校验？
  > - **Gin框架** 使用 **`github.com/go-playground/validator`** 插件进行 **参数校验**。
  > - 在 **struct 结构体** 添加 **`binding` 标签**，然后调用 **`ShouldBing`** 方法。
- ## Gin框架如何实现跨域？
  > - 1.写一个 中间件 来配置 跨域。
  > - 2.使用官网提供的 插件: github.com/gin-contrib/cors。
- ## Gin框架 响应请求方式有哪几种？
  > 以`字符串`方式: c.String(http.StatusOK, "hello world")
  > 以`json`格式: c.JSON(http.StatusOK, gin.H{ }）
  ## Gin框架 中 Gin.H 代表什么意思？
  > - **`gin.H`** 实际上就是 **`map[string]interface{}`**。
  > - 引入 **gin.H** 可以简化生成 **json** 的方式，**gin.H** 可以 **嵌套使用**。
- # GORM
- ## 什么是 ORM 框架？
  **对象-关系映射(ORM)系统**，实现了 **程序对象 到 关系数据库数据 的映射。**
- ## 事务处理 有哪些主要注意的点？
- 首先启动事务时一定要做 **错误判断**。
- 建议在 **启动事务** 之后马上写 **defer方法**。
- 在 **defer方法** 内对 **err** 进行判断，如果 **全局** 中有 **err!=nil** 就回滚 (全局中 **err** 都为 **nil** 才能 **提交事务**)
- 在 **提交事务** 之后我们可以定义一个 **钩子函数 afterCommit**，来统一处理事务提交后的 **逻辑**。
- ## 使用orm的好处
- 提高开发效率（自动化生成SQL，减少手动编写SQL时间）
- 只需要定义好模型，可以自动处理不同数据库之间的差异；(如果传统编写，换数据库相当于需要吧原来的逻辑重写一遍)
- 易于维护，方便拓展（传统编写SQL如果多起来，排查问题和重构时很痛苦）；
- 安全，参数化查询避免SQL注入
- # DDD
- # Goframe
- ## 什么是 GoFrame？与 Go 标准库有什么区别？
  
  GoFrame 是一个强大的 Go Web 应用开发框架，它提供了一系列优秀的功能模块和常用工具，方便开发者快速构建高性能、高可用的 Web 应用程序。
  相较于 Go 标准库，GoFrame 提供了更多的功能模块，例如：ORM、Cache、Session、WebSocket、邮件发送等等。此外，GoFrame 也提供了更友好的 API 和更好的性能。
- ## goframe框架中，如何使用中间件？
  在goframe框架中使用中间件很简单。只需要在路由定义时使用中间件函数，例如：
  ``` golang
  s := g.Server()  
  s.Group("/", func(group *ghttp.RouterGroup) {  
    group.Middleware(MiddlewareFunc)  
    group.ALL("/user", UserHandler)  
  })
  ```
- ## goframe框架中，如何实现定时任务？
  在goframe框架中实现定时任务很容易。可以使用gcron插件。该插件提供了简单的API用于创建和管理定时任务，例如：
  ``` golang
  // 创建定时任务  
  s := gcron.NewScheduler()  
  s.Every(1).Hour().Do(TaskFunc)  
  
  // 开始定时任务  
  s.Start()
  ```
- ## goframe框架中，如何实现文件上传和下载？
  ``` golang
  // 文件上传  
  uploadFile, err := r.UploadFile("file")  
  if err != nil {  
    return err  
  }  
  uploadFile.Save("/path/to/save")  
  
  // 文件下载  
  r.Response().Header().Set("Content-Disposition", fmt.Sprintf("attachment; filename=%s", filename))  
  r.Response().ServeFile(filepath)
  ```
- ## GoFrame 中的 gvalid 组件是什么？如何使用？
  goframe框架提供了功能强大、使用便捷、灵活易扩展的数据/表单校验组件，由gvalid组件实现。
  gvalid组件实现了非常强大的数据校验功能，内置了数十种常用的校验规则，支持单数据多规则校验、多数据多规则批量校验、自定义错误信息、自定义正则校验、自定义校验规则注册、支持i18n国际化处理、支持struct tag规则及提示信息绑定等等特性，是目前功能最强大的Go数据校验模块。
- # 微服务
- ## 什么是微服务
  微服务是一种开发软件的架构和组织方法，其中软件由通过明确定义的 API 进行通信的小型独立服务组成。这些服务由各个小型独立团队负责。  
  微服务架构使应用程序更易于扩展和更快地开发，从而加速创新并缩短新功能的上市时间。
- ## 微服务架构的优点和缺点是什么？
  | **微服务架构的优点**  | **微服务架构的缺点**  |
  | ------------- | ------------- |
  | 可以自由使用不同的技术   | 增加故障排除的难度     |
  | 每个微服务都专注于单一功能 | 由于远程调用而导致延迟增加 |
  | 支持单个可部署单元     | 增加配置和其他操作的工作量 |
  | 允许软件的持续发布     | 难以维持处理的安全性    |
  | 可确保每项服务的安全性   | 很难跟踪各种边界的数据   |
  | 并行开发和部署多个服务   | 服务之间难以编码      |
- ## 熔断处理
  服务的熔断及降级是系统鲁棒性的关键之一，这与我们常听说的服务雪崩有着紧密的关系。
  鲁棒性（Robustness）意为健壮、强壮，在计算中指的是系统的健壮性，用于表示容忍可能影响系统功能的扰动的能力
- ### 服务雪崩
  下层的服务因为某些原因（到达性能极限、未知bug、网络分区等）导致访问很慢，如果没有服务的熔断与降级那么该服务的调用者，上层服务会以为这个服务异常而累积过多请求导致产生大量等待的线程，上层服务也会引发访问慢或中止服务的问题。
- ### 解决办法
  设置每个请求的超时时间，超时N次就不再请求。再套用上图的例子我们发现这的确起到立竿见影的效果，可有效地防止雪崩，这也是服务熔断的核心实现之一。
  更好的做法是可以自动探测服务是否正常以进行熔断和恢复请求。比如我们的规则可以修改成：请求超时N次后在X时间不再请求实现熔断，X时间后恢复M%的请求，如果M%的请求都成功（未超时）则恢复正常关闭熔断，否则再熔断Y时间，依此循环。
- ### 更优雅的方式是实现服务降级
  即在依赖服务异常后可以有替代的逻辑以提供备用，比如某一流程很重要，在依赖的服务异常后我们尝试让调用方临时查询依赖服务的缓存数据，缓存数据的实时性可能比较低，但不失为一种临时的解决方案。
  
  <font color="#ff0000">其核心是通过熔断实现服务保护，它体现在对请求做限流或排队以防止并发超过服务预设指标，通过熔断及智能的恢复防止系统雪崩，引入可选的降级流程提升服务的可用性。</font>
- ## 限流
- 防止被突发流量冲垮
- 防止恶意请求和攻击
- 保证集群服务中心的健康稳定运行（流量整形）
- API经济的细粒度资源量（请求量）控制
- ### 限流指标
  1. TPS：（Transactions Per Second）是指每秒事务数。一个事务是指事务内第一个请求发送到接收到最后一个请求的响应的过程，以此来计算使用的时间和完成的事务个数。
  2. HPS：（Hits Per Second）指每秒点击次数（每秒钟服务端收到客户端的请求数量）是指在一秒钟的时间内用户对Web页面的链接、提交按钮等点击总和。 它一般和TPS成正比关系，是B/S系统中非常重要的性能指标之一。
  3. QPS：（Queries Per Second）是指每秒查询率。是一台服务器每秒能够响应的查询次数（数据库中的每秒执行查询sql的次数），显然这个不够全面，不能描述增删改，所以不建议用QPS来作为系统性能指标。
- ### 限流方案
  1. 固定窗口计数器(Fixed Window)：维护一个固定单位时间内的计数器，如果检测到单位时间已经过去就重置计数器为零。计数限首先维护一个计数器，将单位时间段当做一个窗口，计数器记录这个窗口接收请求的次数。
	- 当次数少于限流阀值，就允许访问，并且计数器+1
	- 当次数大于限流阀值，就拒绝访问
	- 当前的时间窗口过去之后，计数器清零
	  2. 滑动窗口计数器：它将单位时间周期分为n个小周期，分别记录每个小周期内接口的访问次数，并且根据时间滑动删除过期的小周期。
	  3. 漏桶算法：
	- 请求来了放入桶中
	- 桶内请求量满了拒绝请求
	- 服务定速从桶内拿请求处理
	  4. 令牌桶算法：
	  令牌桶和漏桶的原理类似，不过漏桶是**定速地流出**，而令牌桶是**定速地往桶里塞入令牌**，然后请求只有拿到了令牌才能通过，之后再被服务器处理。当然令牌桶的大小也是有限制的，假设桶里的令牌满了之后，定速生成的令牌会丢弃。规则：
	- 定速的往桶内放入令牌
	- 令牌数量超过桶的限制，丢弃
	- 请求来了先向桶内索要令牌，索要成功则通过被处理，反之拒绝